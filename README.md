# ğŸ•·ï¸ Web Scraper Institucional

Sistema de scraping inteligente para extrair informaÃ§Ãµes institucionais e de contato de websites, com suporte para SPAs (Single Page Applications) e geraÃ§Ã£o automÃ¡tica de documentaÃ§Ã£o em Markdown.

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Tecnologias](#tecnologias)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
  - [API Server](#api-server)
  - [CLI](#cli)
- [Endpoints da API](#endpoints-da-api)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Output](#output)
- [Exemplos](#exemplos)

## âœ¨ CaracterÃ­sticas

- **Scraping Inteligente**: Detecta e navega automaticamente por pÃ¡ginas institucionais (sobre, contato, polÃ­ticas, etc.)
- **Suporte a SPAs**: Otimizado para React, Vue e outros frameworks modernos usando Puppeteer
- **ExtraÃ§Ã£o de Contatos**: Captura emails, telefones, redes sociais e endereÃ§os automaticamente
- **GeraÃ§Ã£o de Markdown**: Converte todo o conteÃºdo extraÃ­do em documentos Markdown organizados
- **API AssÃ­ncrona**: Processamento em background com sistema de jobs e consulta de status
- **CLI Standalone**: Execute scraping diretamente via linha de comando
- **Filtros AvanÃ§ados**: Evita pÃ¡ginas de produtos e foca em conteÃºdo institucional

## ğŸ› ï¸ Tecnologias

- **Node.js** + **TypeScript**
- **Express** - API REST
- **Puppeteer** - AutomaÃ§Ã£o de navegador e scraping de SPAs
- **Cheerio** - Parse e manipulaÃ§Ã£o de HTML
- **Turndown** - ConversÃ£o de HTML para Markdown
- **Zod** - ValidaÃ§Ã£o de schemas

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <seu-repositorio>
cd web-scraper

# Instale as dependÃªncias
yarn install

# Configure o Chrome/Chromium (se necessÃ¡rio)
# O Puppeteer irÃ¡ baixar automaticamente, mas vocÃª pode configurar o caminho:
export PUPPETEER_CACHE_DIR=/caminho/para/chrome
```

## ğŸš€ Uso

### API Server

Inicie o servidor da API:

```bash
# Modo desenvolvimento (com hot-reload)
yarn dev

# Modo produÃ§Ã£o
yarn start
```

O servidor serÃ¡ iniciado em `http://localhost:3000`

### CLI

Execute scraping diretamente via linha de comando:

```bash
yarn tsx cli.ts https://www.exemplo.com.br

```

## ğŸ“¡ Endpoints da API

### POST /scrape

Inicia um processo de scraping assÃ­ncrono.

**Request:**
```json
{
  "url": "https://www.exemplo.com.br",
  "options": {
    "timeout": 30000,
    "waitUntil": "networkidle2"
  }
}
```

**Response (202 Accepted):**
```json
{
  "success": true,
  "jobId": "550e8400-e29b-41d4-a716-446655440000",
  "statusUrl": "http://localhost:3000/status/550e8400-e29b-41d4-a716-446655440000",
  "message": "Scraping iniciado. Use o statusUrl para acompanhar."
}
```

### GET /status/:jobId

Consulta o status de um job de scraping.

**Response (Processando):**
```json
{
  "status": "processing",
  "url": "https://www.exemplo.com.br",
  "elapsed": "3.45s"
}
```

**Response (ConcluÃ­do):**
```json
{
  "status": "completed",
  "duration": "12.34s",
  "data": {
    "url": "https://www.exemplo.com.br",
    "markdownFile": "/caminho/para/outputs/exemplo-com-br_2026-02-06_550e8400.md",
    "stats": {
      "pagesScraped": 8,
      "totalInstitutional": 5
    },
    "metadata": {
      "title": "Exemplo Loja",
      "description": "DescriÃ§Ã£o do site",
      "siteName": "Exemplo"
    },
    "contactInfo": {
      "emails": ["contato@exemplo.com.br"],
      "phones": ["(11) 98765-4321"],
      "socialMedia": {
        "instagram": "https://instagram.com/exemplo",
        "facebook": "https://facebook.com/exemplo"
      },
      "addresses": []
    },
    "storeInfo": {
      "name": "Exemplo Loja Ltda",
      "cnpj": "12.345.678/0001-90"
    }
  }
}
```

**Response (Falhou):**
```json
{
  "status": "failed",
  "error": "Timeout ao acessar a pÃ¡gina"
}
```

### GET /health

Health check da API.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2026-02-06T17:35:00.000Z",
  "activeJobs": 3
}
```

## ğŸ“ Estrutura do Projeto

```
web-scraper/
â”œâ”€â”€ index.ts                 # API Server Express
â”œâ”€â”€ cli.ts                   # Script CLI standalone
â”œâ”€â”€ scraper.service.ts       # ServiÃ§o principal de scraping
â”œâ”€â”€ markdown-generator.ts    # Gerador de documentos Markdown
â”œâ”€â”€ types.ts                 # Interfaces TypeScript
â”œâ”€â”€ outputs/                 # Arquivos Markdown gerados
â”‚   â””â”€â”€ exemplo-com-br_2026-02-06_550e8400.md
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# Porta do servidor (padrÃ£o: 3000)
PORT=3000

# Caminho do executÃ¡vel do Chrome (opcional)
PUPPETEER_CACHE_DIR=/usr/bin/google-chrome-stable
```

### OpÃ§Ãµes de Scraping

| OpÃ§Ã£o | Tipo | PadrÃ£o | DescriÃ§Ã£o |
|-------|------|--------|-----------|
| `timeout` | number | 30000 | Timeout em ms para cada pÃ¡gina |
| `waitUntil` | string | 'networkidle2' | CondiÃ§Ã£o de espera: 'load', 'domcontentloaded', 'networkidle0', 'networkidle2' |

### Limites e Filtros

- **Profundidade mÃ¡xima**: 12 pÃ¡ginas institucionais por site
- **Timeout de jobs**: Jobs sÃ£o removidos da fila apÃ³s 1 hora de conclusÃ£o
- **Filtros de conteÃºdo**: Exclui automaticamente pÃ¡ginas de produtos, carrinho e checkout

## ğŸ“„ Output

Os arquivos Markdown gerados seguem esta estrutura:

```markdown
# Nome da Loja

**Site:** https://www.exemplo.com.br
**DescriÃ§Ã£o:** DescriÃ§Ã£o do site
**Nome da Empresa:** Exemplo Loja Ltda
**Data da Coleta:** 06/02/2026

---

## ğŸ“ InformaÃ§Ãµes de Contato

**Emails:**
- contato@exemplo.com.br
- vendas@exemplo.com.br

**Telefones:**
- (11) 98765-4321
- (11) 3456-7890

**Redes Sociais:**
- WhatsApp: https://wa.me/5511987654321
- Instagram: https://instagram.com/exemplo
- Facebook: https://facebook.com/exemplo

---

## ğŸ¢ Dados da Empresa

**Nome:** Exemplo Loja Ltda
**CNPJ:** 12.345.678/0001-90

---

## ğŸ“„ ConteÃºdo Institucional

### Sobre NÃ³s

[ConteÃºdo da pÃ¡gina sobre...]

### PolÃ­tica de Privacidade

[ConteÃºdo da pÃ¡gina de polÃ­tica...]
```

## ğŸ’¡ Exemplos

### Exemplo 1: Uso da API

```bash
# 1. Inicia o scraping
curl -X POST http://localhost:3000/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.loja-exemplo.com.br"}'

# Resposta:
# {
#   "jobId": "abc-123",
#   "statusUrl": "http://localhost:3000/status/abc-123"
# }

# 2. Consulta o status
curl http://localhost:3000/status/abc-123

# 3. Quando concluÃ­do, o arquivo markdown estarÃ¡ em outputs/
```

### Exemplo 2: Uso do CLI

```bash
# Scraping simples
yarn run cli https://www.loja-exemplo.com.br

# Output no terminal:
# ============================================================
# âœ… SCRAPING CONCLUÃDO EM 15.32s
# ============================================================
# 
# ğŸ“Š Resumo:
#    ğŸ“„ PÃ¡ginas processadas: 10
#    ğŸ“‹ PÃ¡ginas institucionais: 6
#    ğŸ“§ Emails encontrados: 2
#    ğŸ“ Telefones encontrados: 3
#    ğŸŒ Redes sociais: 4
#    ğŸ“„ Markdown salvo em: outputs/loja-exemplo-com-br_2026-02-06_cli-1738869300123.md
# ============================================================
```

### Exemplo 3: IntegraÃ§Ã£o com TypeScript

```typescript
import { scraperService } from './scraper.service.js';
import { MarkdownGenerator } from './markdown-generator.js';

async function meuScraper() {
  const result = await scraperService.scrapeUrl('https://exemplo.com', {
    timeout: 30000,
    waitUntil: 'networkidle2'
  });

  const markdownPath = MarkdownGenerator.generateAndSave(result, 'custom-id');

  console.log('Markdown salvo em:', markdownPath);
  console.log('Emails encontrados:', result.contactInfo.emails);
}
```

## ğŸ”§ Scripts DisponÃ­veis

| Script | Comando | DescriÃ§Ã£o |
|--------|---------|-----------|
| Desenvolvimento | `yarn dev` | Inicia API com hot-reload |
| ProduÃ§Ã£o | `yarn start` | Inicia API em modo produÃ§Ã£o |
| CLI | `yarn run cli <URL>` | Executa scraping via linha de comando |
| Build | `yarn run build` | Compila TypeScript para JavaScript |

## ğŸ› Troubleshooting

### Puppeteer nÃ£o encontra o Chrome

```bash
# Linux
sudo apt-get install -y chromium-browser

# Mac
brew install chromium

# Ou configure manualmente:
export PUPPETEER_CACHE_DIR=/caminho/para/chrome
```

### Timeout em sites lentos

Aumente o timeout nas opÃ§Ãµes:

```json
{
  "url": "https://site-lento.com",
  "options": {
    "timeout": 60000,
    "waitUntil": "domcontentloaded"
  }
}
```

### ConteÃºdo nÃ£o estÃ¡ sendo capturado

Para SPAs com muito JavaScript, use `networkidle0`:

```json
{
  "options": {
    "waitUntil": "networkidle0"
  }
}
```

## ğŸ“ LicenÃ§a

MIT

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido com â˜• e ğŸ’»

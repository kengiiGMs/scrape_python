# Explica√ß√£o Completa: Sistema de Ingest√£o Ag√™ntica de FAQs

## üéØ Vis√£o Geral

O `ingest_faq.py` √© um **agente de ingest√£o inteligente** que transforma arquivos Markdown brutos (scraped) em FAQs estruturados e otimizados para busca vetorial. Diferente de sistemas tradicionais que simplesmente cortam texto em chunks, este usa um LLM para **limpar, estruturar e enriquecer** os dados antes de inseri-los no banco vetorial.

## üîÑ Problema que Resolve

### ‚ùå Abordagem Tradicional (Problem√°tica)

```python
# Sistema antigo (agent_rag.py original)
1. L√™ plantie.md inteiro
2. Corta em peda√ßos de 1000 caracteres (chunks)
3. Vetoriza cada chunk
4. Insere no banco
```

**Problemas:**
- ‚úó Inclui ru√≠do (menus, rodap√©s, copyright)
- ‚úó Quebra contexto no meio de frases
- ‚úó Busca retorna trechos incompletos
- ‚úó Dif√≠cil de manter/atualizar

### ‚úÖ Nova Abordagem (Ingest√£o Ag√™ntica)

```python
# Sistema novo (ingest_faq.py)
1. L√™ plantie.md inteiro
2. LLM analisa e extrai FAQs estruturados
3. Remove ru√≠do e enriquece com varia√ß√µes sint√©ticas
4. Vetoriza FAQs completos
5. Insere no banco com metadados
```

**Vantagens:**
- ‚úì Dados limpos e estruturados
- ‚úì FAQs completos e autossuficientes
- ‚úì Varia√ß√µes sint√©ticas aumentam recall
- ‚úì Metadados (categoria, tags, audience)
- ‚úì Reus√°vel para qualquer arquivo .md

## üèóÔ∏è Arquitetura do Sistema

```mermaid
flowchart TD
    A[Arquivo Markdown Bruto] --> B[TextLoader]
    B --> C{LLM + System Prompt}
    C --> D[JSON com FAQs]
    D --> E[Valida√ß√£o Pydantic]
    E --> F[Gera Embeddings]
    F --> G[Concatena: question + answer + variations]
    G --> H[(Supabase Vector Store)]
    H --> I[Chatbot RAG]
    
    style C fill:#4CAF50
    style E fill:#2196F3
    style H fill:#FF9800
```

## üìã Componentes Principais

### 1. **System Prompt (O C√©rebro do Agente)**

Localiza√ß√£o: Linhas 22-131

O prompt est√° dividido em 6 se√ß√µes:

#### 1.1. Objetivo
Define a miss√£o do agente: transformar Markdown bruto em FAQs estruturados.

#### 1.2. Regras de Limpeza (Negative Constraints)

```python
# O que IGNORAR:
- Navega√ß√£o (breadcrumbs, menus)
- Marketing (CTAs, "Assine agora")
- Conte√∫do din√¢mico (not√≠cias datadas)
- Boilerplate legal (copyright gen√©rico)
```

**Por qu√™?** Esses elementos poluem os vetores e geram falsos positivos na busca.

#### 1.3. Regras de Transforma√ß√£o

**Single-Topic Chunking:**
```markdown
# Entrada:
"Para usu√°rios Basic, limite √© 10GB. Para usu√°rios Pro, limite √© ilimitado."

# Sa√≠da:
FAQ 1: "Qual o limite para usu√°rios Basic?" ‚Üí "10GB"
FAQ 2: "Qual o limite para usu√°rios Pro?" ‚Üí "Ilimitado"
```

**Contextualiza√ß√£o (De-referencing):**
```markdown
# Ruim:
"Clique nele para salvar."

# Bom:
"Clique no bot√£o 'Salvar' no painel de configura√ß√µes."
```

#### 1.4. Taxonomia de Categorias

```python
CATEGORIAS = [
    "Troubleshooting",           # Erros e problemas
    "How-To & Configuration",    # Tutoriais
    "Billing & Account",         # Financeiro
    "Product Info",              # Funcionalidades
    "Policies & Compliance",     # Legal
    "General"                    # Informa√ß√µes gerais
]
```

#### 1.5. Gera√ß√£o de Varia√ß√µes Sint√©ticas

```json
{
  "question": "Como resetar a senha?",
  "synthetic_variations": [
    "esqueci minha senha o que fazer",      // Coloquial
    "n√£o consigo logar senha incorreta",    // Baseado em sintoma
    "recuperar acesso conta"                // Keywords
  ]
}
```

**Impacto:** Aumenta em ~40% a chance de match sem√¢ntico (fonte: doc.md).

#### 1.6. Formato de Sa√≠da (JSON Schema)

```json
{
  "faq_items": [
    {
      "question": "string",
      "synthetic_variations": ["string", "string"],
      "answer": "markdown",
      "category": "enum",
      "tags": ["string"],
      "audience": "string",
      "confidence_score": 0.0-1.0
    }
  ]
}
```

### 2. **Modelos Pydantic (Valida√ß√£o)**

Arquivo: `models.py`

```python
class FAQItem(BaseModel):
    question: str
    synthetic_variations: List[str]  # Min: 1
    answer: str
    category: str                     # Validado contra lista
    tags: List[str]
    audience: str
    confidence_score: float           # 0.0 a 1.0

class FAQResponse(BaseModel):
    faq_items: List[FAQItem]          # Min: 1
```

**Por qu√™ Pydantic?**
- Valida estrutura antes de inserir no banco
- Previne erros de tipo
- Documenta√ß√£o autom√°tica

### 3. **Pipeline de Ingest√£o**

#### Passo 1: Carregamento (`load_markdown_file`)

```python
# Linhas 134-147
loader = TextLoader(file_path, encoding="utf-8")
documents = loader.load()
content = documents[0].page_content
```

**Detalhe importante:** UTF-8 para suportar caracteres especiais.

#### Passo 2: Processamento com LLM (`process_with_llm`)

```python
# Linhas 150-193
messages = [
    {"role": "system", "content": INGESTION_SYSTEM_PROMPT},
    {"role": "user", "content": content}
]

response = llm.invoke(messages)
```

**Extra√ß√£o do JSON:**
```python
# Lida com casos onde o LLM adiciona markdown
if "```json" in raw_response:
    json_str = raw_response.split("```json")[1].split("```")[0]
```

**Valida√ß√£o:**
```python
parsed_json = json.loads(json_str)
faq_response = FAQResponse(**parsed_json)  # Pydantic valida
```

#### Passo 3: Gera√ß√£o de Embeddings (`generate_embeddings_for_faqs`)

```python
# Linhas 196-233
# Estrat√©gia: Concatenar tudo para vetor rico
text_to_embed = (
    f"{faq.question}\n\n"
    f"{faq.answer}\n\n"
    f"{' '.join(faq.synthetic_variations)}"
)

# Gera vetores em batch (eficiente)
vectors = embeddings.embed_documents(texts_to_embed)
```

**Por qu√™ concatenar?**
- Vetor captura m√∫ltiplas formas de perguntar a mesma coisa
- Aumenta a "superf√≠cie de contato" no espa√ßo vetorial
- Melhora recall sem prejudicar precision

#### Passo 4: Prepara√ß√£o dos Dados

```python
# Linhas 224-233
rows.append({
    "content": faq.answer,      # O que ser√° retornado ao chatbot
    "metadata": {               # Metadados para filtros
        "question": faq.question,
        "synthetic_variations": faq.synthetic_variations,
        "category": faq.category,
        "tags": faq.tags,
        "audience": faq.audience,
        "confidence_score": faq.confidence_score
    },
    "embedding": vectors[i]     # Vetor de 768 dimens√µes
})
```

#### Passo 5: Inser√ß√£o no Supabase (`insert_into_supabase`)

```python
# Linhas 236-277
if clear_before:
    supabase.table(table_name).delete().neq('id', 0).execute()

supabase.table(table_name).insert(rows).execute()
```

**Flag `--clear`:** Limpa tabela antes de inserir (evita duplicatas).

## üîß Como Usar

### Configura√ß√£o Inicial

1. **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

2. **Configure o `.env`:**
```env
GOOGLE_API_KEY=sua_chave_google_ai
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_KEY=sua_chave_service_role
```

### Execu√ß√£o

```bash
# Sintaxe b√°sica
python ingest_faq.py --input <arquivo.md> [op√ß√µes]

# Exemplo: Processar plantie.md e limpar tabela antes
python ingest_faq.py --input plantie.md --table marketing_rag --clear

# Exemplo: Processar outro arquivo sem limpar
python ingest_faq.py --input outro_site.md --table marketing_rag
```

### Par√¢metros

| Par√¢metro | Obrigat√≥rio | Padr√£o | Descri√ß√£o |
|-----------|-------------|--------|-----------|
| `--input` | ‚úì | - | Caminho do arquivo .md a processar |
| `--table` | ‚úó | `marketing_rag` | Nome da tabela no Supabase |
| `--clear` | ‚úó | `False` | Limpa tabela antes de inserir |

## üìä Output Exemplo

```
================================================================================
SISTEMA DE INGESTAO AGENTICA DE FAQs
================================================================================

Configurando sistema...
Sistema configurado!
Carregando arquivo: plantie.md
Arquivo carregado com sucesso! (20608 caracteres)

Enviando para o LLM processar...
LLM retornou resposta (15234 caracteres)
JSON validado com sucesso! 28 FAQs encontrados.

Gerando embeddings para os FAQs...
28 embeddings gerados com sucesso!

Limpando tabela 'marketing_rag'...
Tabela 'marketing_rag' limpa com sucesso!

Inserindo 28 FAQs na tabela 'marketing_rag'...
28 FAQs inseridos com sucesso no Supabase!

================================================================================
INGESTAO CONCLUIDA COM SUCESSO!
================================================================================

Estatisticas:
   - Arquivo processado: plantie.md
   - FAQs gerados: 28
   - Tabela: marketing_rag
   - Modo clear: Sim

FAQs por categoria:
   - Product Info: 12
   - How-To & Configuration: 8
   - General: 5
   - Billing & Account: 3
```

## üéØ Diferen√ßas vs Sistema Antigo

| Aspecto | Sistema Antigo (agent_rag.py) | Sistema Novo (ingest_faq.py) |
|---------|-------------------------------|------------------------------|
| **Processamento** | Chunking cego (1000 chars) | LLM estrutura FAQs |
| **Qualidade** | Chunks com ru√≠do | FAQs limpos |
| **Contexto** | Pode quebrar no meio | FAQs completos |
| **Busca** | Apenas similaridade | Similaridade + varia√ß√µes |
| **Metadados** | S√≥ `source` | Categoria, tags, audience |
| **Manuten√ß√£o** | Re-inserir tudo | Atualizar FAQs espec√≠ficos |
| **Reusabilidade** | Hardcoded para plantie.md | Funciona para qualquer .md |

## üî¨ Detalhes T√©cnicos Avan√ßados

### Modelo LLM Usado

```python
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash-latest",
    temperature=0  # Determin√≠stico
)
```

**Por qu√™ Flash e n√£o Pro?**
- Mais r√°pido (3-5s vs 10-20s)
- Mais barato ($0.0001/1K tokens vs $0.001)
- Suficiente para extra√ß√£o estruturada
- Para tarefas de limpeza, velocidade > criatividade

### Embeddings

```python
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/gemini-embedding-001"
)
```

- **Dimens√µes:** 768
- **Modelo:** text-embedding-004 (√∫ltima vers√£o do Gemini)
- **Compat√≠vel** com Supabase pgvector

### Estrat√©gia de Batching

```python
# Gera TODOS os embeddings de uma vez (n√£o um por um)
vectors = embeddings.embed_documents(texts_to_embed)
```

**Vantagem:** ~10x mais r√°pido que loop individual.

## ‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes

### 1. Custo do LLM

**Estimativa para plantie.md (20KB):**
- Input tokens: ~5,000
- Output tokens: ~3,000
- Custo total: ~$0.0008 (menos de 1 centavo)

**Otimiza√ß√£o:** Use `gemini-1.5-flash-latest` em vez de `gemini-pro`.

### 2. Tempo de Processamento

- Arquivo pequeno (20KB): ~15-30 segundos
- Arquivo m√©dio (100KB): ~1-2 minutos
- Arquivo grande (500KB): ~5-10 minutos

**Gargalo:** Chamada ao LLM (n√£o tem como paralelizar).

### 3. Qualidade do Output

O LLM pode ocasionalmente:
- Gerar categorias erradas (valida√ß√£o Pydantic pega)
- Criar FAQs muito gen√©ricos (ajuste o prompt)
- Perder informa√ß√µes muito t√©cnicas (revise manualmente)

**Solu√ß√£o:** Use `confidence_score` < 0.7 como flag de revis√£o.

### 4. Handling de Erros

```python
try:
    faq_response = process_with_llm(content, llm)
except ValidationError as e:
    # JSON n√£o passou na valida√ß√£o Pydantic
    print(f"Erro de validacao: {e}")
except json.JSONDecodeError as e:
    # LLM retornou texto quebrado
    print(f"JSON invalido: {e}")
```

## üöÄ Melhorias Futuras

### 1. Suporte a M√∫ltiplos Arquivos

```python
# Futuro:
python ingest_faq.py --input-dir ./scraped_sites/ --clear
```

### 2. Detec√ß√£o de Duplicatas Inteligente

```python
# Usar hash do conte√∫do + similaridade vetorial
# para evitar re-inserir FAQs id√™nticos
```

### 3. Fine-tuning do Prompt

```python
# Permitir carregar prompts customizados
python ingest_faq.py --input site.md --prompt custom_prompt.txt
```

### 4. Interface Web

```python
# Streamlit/Gradio para upload de arquivos
# e visualiza√ß√£o dos FAQs gerados antes de inserir
```

### 5. Versionamento de FAQs

```python
# Manter hist√≥rico de vers√µes
# para rollback e A/B testing
```

## üîó Integra√ß√£o com agent_rag.py

```mermaid
sequenceDiagram
    participant User
    participant ingest_faq
    participant LLM
    participant Supabase
    participant agent_rag
    
    User->>ingest_faq: python ingest_faq.py --input plantie.md
    ingest_faq->>LLM: Markdown bruto
    LLM->>ingest_faq: FAQs estruturados (JSON)
    ingest_faq->>Supabase: INSERT FAQs vetorizados
    
    Note over Supabase: FAQs prontos para busca
    
    User->>agent_rag: "Como entrar em contato?"
    agent_rag->>Supabase: Busca vetorial
    Supabase->>agent_rag: Top 4 FAQs relevantes
    agent_rag->>LLM: Sintetiza resposta
    LLM->>agent_rag: Resposta final
    agent_rag->>User: "Voc√™ pode entrar em contato via..."
```

## üìö Refer√™ncias

1. **doc.md** - Relat√≥rio t√©cnico completo sobre ingest√£o ag√™ntica
2. **models.py** - Schemas Pydantic
3. **agent_rag.py** - Agente conversacional que consome os FAQs
4. **Supabase Docs** - https://supabase.com/docs/guides/ai

## üéì Conclus√£o

O `ingest_faq.py` representa a **evolu√ß√£o de sistemas RAG passivos para sistemas RAG cognitivos**. Ao mover a complexidade para o momento da ingest√£o (n√£o da busca), garantimos:

1. ‚úÖ **Qualidade**: Dados limpos e estruturados
2. ‚úÖ **Performance**: Busca mais r√°pida (menos chunks, mais relevantes)
3. ‚úÖ **Manutenibilidade**: F√°cil atualizar/adicionar FAQs
4. ‚úÖ **Escalabilidade**: Funciona para qualquer site/documenta√ß√£o
5. ‚úÖ **Auditabilidade**: Metadados rastreiam origem e confian√ßa

**Next Steps:**
1. Execute `python ingest_faq.py --input plantie.md --clear`
2. Teste o chatbot com `python agent_rag.py`
3. Compare resultados com o sistema antigo
4. Ajuste o prompt conforme necess√°rio

---

**Autor:** Sistema de IA  
**Data:** 10/02/2026  
**Vers√£o:** 1.0

# ğŸ“š DocumentaÃ§Ã£o: Agente_FAQ.py

## ğŸ¯ VisÃ£o Geral

O `Agente_FAQ.py` Ã© um **sistema de ingestÃ£o agÃªntica** que utiliza InteligÃªncia Artificial para processar documentaÃ§Ã£o em formato Markdown e transformÃ¡-la automaticamente em uma base de conhecimento estruturada de FAQs (Perguntas Frequentes).

### O que o script faz?

1. **LÃª** arquivos Markdown brutos (scraped de sites, documentaÃ§Ãµes, etc)
2. **Processa** o conteÃºdo usando LLM (Gemini 2.5 Flash) para extrair informaÃ§Ãµes relevantes
3. **Estrutura** as informaÃ§Ãµes em formato FAQ com perguntas, respostas, categorias e metadados
4. **Gera embeddings** vetoriais dos FAQs usando Gemini Embedding
5. **Armazena** tudo no banco vetorial Supabase para consulta por similaridade
6. **Rastreia** o consumo de tokens da operaÃ§Ã£o

---

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Arquivo .md     â”‚
â”‚ (Markdown bruto)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. load_markdown_file() â”‚
â”‚    - Carrega arquivo    â”‚
â”‚    - Valida conteÃºdo    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. process_with_llm()       â”‚
â”‚    - Envia para Gemini      â”‚
â”‚    - System Prompt inteli.  â”‚
â”‚    - Extrai FAQs estrut.    â”‚
â”‚    - Rastreia tokens        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. generate_embeddings()     â”‚
â”‚    - Cria vetores semÃ¢nticos â”‚
â”‚    - Concatena Q+A+variaÃ§Ãµes â”‚
â”‚    - Estima tokens usado     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. insert_into_supabase()    â”‚
â”‚    - Insere no banco vetorialâ”‚
â”‚    - OpÃ§Ã£o de limpar tabela  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Componentes Principais

### 1. TokenUsageTracker (Classe)

**PropÃ³sito**: Rastrear o consumo de tokens durante a operaÃ§Ã£o.

**Atributos**:
- `llm_input_tokens`: Tokens de entrada do LLM
- `llm_output_tokens`: Tokens de saÃ­da do LLM
- `llm_total_tokens`: Total de tokens do LLM
- `embedding_tokens`: Tokens usados nos embeddings

**MÃ©todos**:
- `on_llm_end()`: Callback para capturar tokens (nÃ£o usado diretamente no Gemini)
- `get_summary()`: Retorna dicionÃ¡rio com resumo de uso
- `print_summary()`: Imprime resumo formatado no terminal

**Exemplo de uso**:
```python
tracker = TokenUsageTracker()
faq_response = process_with_llm(content, llm, tracker)
tracker.print_summary()  # Exibe: 15,986 tokens (6,311 entrada + 9,675 saÃ­da)
```

---

### 2. INGESTION_SYSTEM_PROMPT (Constante)

**PropÃ³sito**: System prompt que instrui o LLM sobre como processar o conteÃºdo.

**Principais Diretrizes**:

#### 2.1 O que Ignorar
- âŒ Elementos de navegaÃ§Ã£o (menus, breadcrumbs, rodapÃ©s)
- âŒ ConteÃºdo promocional e CTAs
- âŒ Listas dinÃ¢micas (posts recentes, notÃ­cias)
- âŒ Boilerplate legal genÃ©rico

#### 2.2 Como Processar
- âœ… **Single-Topic Chunking**: Um tÃ³pico por FAQ
- âœ… **ContextualizaÃ§Ã£o**: Substituir pronomes vagos por referÃªncias explÃ­citas
- âœ… **FormataÃ§Ã£o Markdown**: Usar negrito, listas, instruÃ§Ãµes claras

#### 2.3 Taxonomia de Categorias
1. `Troubleshooting` - SoluÃ§Ã£o de problemas e erros
2. `How-To & Configuration` - Tutoriais e configuraÃ§Ãµes
3. `Billing & Account` - Faturas, pagamentos, login
4. `Product Info` - Funcionalidades e requisitos
5. `Policies & Compliance` - Termos, privacidade, jurÃ­dico
6. `General` - InformaÃ§Ãµes gerais da empresa

#### 2.4 Query Expansion (VariaÃ§Ãµes SintÃ©ticas)
Para cada FAQ, o LLM gera 2-4 variaÃ§Ãµes de pergunta:
- **VariaÃ§Ã£o Leiga**: Termos menos tÃ©cnicos
- **VariaÃ§Ã£o Sintoma**: Foco no problema, nÃ£o na soluÃ§Ã£o
- **VariaÃ§Ã£o Keywords**: String curta com palavras-chave

**Exemplo**:
```json
{
  "question": "Como resetar a senha?",
  "synthetic_variations": [
    "esqueci minha senha o que fazer",
    "recuperar acesso conta",
    "problema login senha incorreta"
  ]
}
```

---

### 3. load_markdown_file(file_path: str)

**PropÃ³sito**: Carrega arquivo Markdown e retorna seu conteÃºdo.

**ParÃ¢metros**:
- `file_path`: Caminho do arquivo .md

**Retorno**: String com o conteÃºdo completo

**ValidaÃ§Ãµes**:
- âœ… Arquivo existe
- âœ… ConteÃºdo nÃ£o estÃ¡ vazio
- âœ… Encoding UTF-8

**Exemplo de saÃ­da**:
```
Carregando arquivo: plantie.md
Arquivo carregado com sucesso! (20608 caracteres)
```

---

### 4. process_with_llm(content, llm, tracker)

**PropÃ³sito**: Envia conteÃºdo para o LLM e extrai FAQs estruturados.

**ParÃ¢metros**:
- `content`: String com o conteÃºdo Markdown
- `llm`: InstÃ¢ncia do ChatGoogleGenerativeAI
- `tracker`: (Opcional) TokenUsageTracker para rastrear tokens

**Retorno**: Objeto `FAQResponse` (validado com Pydantic)

**Fluxo de Processamento**:

1. **Monta mensagens** (system + user prompt)
2. **Invoca LLM** (Gemini 2.5 Flash)
3. **Captura tokens** do `usage_metadata` da resposta
4. **Extrai JSON** (remove markdown se presente)
5. **Valida** estrutura com Pydantic
6. **Retorna** objeto FAQResponse

**Tratamento de Erros**:
- `JSONDecodeError`: JSON malformado
- `ValidationError`: Estrutura invÃ¡lida do FAQ

**Exemplo de saÃ­da**:
```
Enviando para o LLM processar...
   (LLM usou 15,986 tokens: 6,311 entrada + 9,675 saÃ­da)
LLM retornou resposta (27094 caracteres)
JSON validado com sucesso! 30 FAQs encontrados.
```

---

### 5. generate_embeddings_for_faqs(faq_items, embeddings, tracker)

**PropÃ³sito**: Gera embeddings vetoriais para cada FAQ.

**ParÃ¢metros**:
- `faq_items`: Lista de objetos FAQItem
- `embeddings`: InstÃ¢ncia do GoogleGenerativeAIEmbeddings
- `tracker`: (Opcional) TokenUsageTracker

**Retorno**: Lista de dicionÃ¡rios prontos para inserÃ§Ã£o no Supabase

**Processo**:

1. **Concatena** para cada FAQ:
   ```python
   text_to_embed = f"{question}\n\n{answer}\n\n{' '.join(synthetic_variations)}"
   ```

2. **Gera embeddings em batch** (todos de uma vez para eficiÃªncia)

3. **Estima tokens**: `total_chars / 4` (aproximaÃ§Ã£o)

4. **Monta estrutura final**:
   ```python
   {
       "content": answer,           # Texto retornado ao chatbot
       "metadata": {
           "question": question,
           "synthetic_variations": [...],
           "category": category,
           "tags": [...],
           "audience": audience,
           "confidence_score": 0.9
       },
       "embedding": [0.123, -0.456, ...]  # Vetor de 768 dimensÃµes
   }
   ```

**Exemplo de saÃ­da**:
```
Gerando embeddings para os FAQs...
   (Estimativa: ~4,276 tokens de embeddings)
30 embeddings gerados com sucesso!
```

---

### 6. clear_table(supabase, table_name)

**PropÃ³sito**: Limpa todos os registros da tabela no Supabase.

**ParÃ¢metros**:
- `supabase`: Cliente Supabase
- `table_name`: Nome da tabela

**Comportamento**:
- Usa filtro `.neq('id', 0)` (sempre verdadeiro) para deletar tudo
- Captura exceÃ§Ãµes e continua se falhar

**Exemplo de saÃ­da**:
```
Limpando tabela 'marketing_rag'...
Tabela 'marketing_rag' limpa com sucesso!
```

---

### 7. insert_into_supabase(supabase, table_name, rows, clear_before)

**PropÃ³sito**: Insere FAQs processados no banco vetorial.

**ParÃ¢metros**:
- `supabase`: Cliente Supabase
- `table_name`: Nome da tabela destino
- `rows`: Lista de registros para inserir
- `clear_before`: Se `True`, limpa tabela antes

**Fluxo**:
1. (Opcional) Limpa tabela
2. Insere todos os registros em batch
3. Retorna resultado da operaÃ§Ã£o

**Exemplo de saÃ­da**:
```
Inserindo 30 FAQs na tabela 'marketing_rag'...
30 FAQs inseridos com sucesso no Supabase!
```

---

### 8. main()

**PropÃ³sito**: FunÃ§Ã£o principal que orquestra todo o pipeline.

**Argumentos de Linha de Comando**:

| Argumento | Tipo | ObrigatÃ³rio | PadrÃ£o | DescriÃ§Ã£o |
|-----------|------|-------------|--------|-----------|
| `--input` | string | âœ… Sim | - | Caminho do arquivo .md |
| `--table` | string | âŒ NÃ£o | `marketing_rag` | Nome da tabela Supabase |
| `--clear` | flag | âŒ NÃ£o | `False` | Limpar tabela antes de inserir |

**Pipeline Completo**:

```python
# 1. ConfiguraÃ§Ã£o
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
supabase = create_client(supabase_url, supabase_key)
tracker = TokenUsageTracker()

# 2. Carrega arquivo
content = load_markdown_file(args.input)

# 3. Processa com LLM
faq_response = process_with_llm(content, llm, tracker)

# 4. Gera embeddings
rows = generate_embeddings_for_faqs(faq_response.faq_items, embeddings, tracker)

# 5. Insere no banco
insert_into_supabase(supabase, args.table, rows, clear_before=args.clear)

# 6. EstatÃ­sticas
tracker.print_summary()
```

---

## ğŸš€ Como Usar

### PrÃ©-requisitos

**1. VariÃ¡veis de Ambiente** (`.env`):
```env
GOOGLE_API_KEY=sua_chave_api_google
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_KEY=sua_chave_service
```

**2. DependÃªncias Python**:
```bash
pip install langchain-google-genai langchain-community supabase python-dotenv pydantic
```

**3. Arquivo `models.py`** com as classes Pydantic:
```python
from pydantic import BaseModel
from typing import List

class FAQItem(BaseModel):
    question: str
    synthetic_variations: List[str]
    answer: str
    category: str
    tags: List[str]
    audience: str
    confidence_score: float

class FAQResponse(BaseModel):
    faq_items: List[FAQItem]
```

### ExecuÃ§Ã£o BÃ¡sica

```bash
python Agente_FAQ.py --input documento.md --table marketing_rag
```

### ExecuÃ§Ã£o com Limpeza de Tabela

```bash
python Agente_FAQ.py --input documento.md --table marketing_rag --clear
```

### Exemplo de SaÃ­da Completa

```
================================================================================
SISTEMA DE INGESTAO AGENTICA DE FAQs
================================================================================

Configurando sistema...
Sistema configurado!
Carregando arquivo: plantie.md
Arquivo carregado com sucesso! (20608 caracteres)

Enviando para o LLM processar...
   (LLM usou 15,986 tokens: 6,311 entrada + 9,675 saÃ­da)
LLM retornou resposta (27094 caracteres)
JSON validado com sucesso! 30 FAQs encontrados.

Gerando embeddings para os FAQs...
   (Estimativa: ~4,276 tokens de embeddings)
30 embeddings gerados com sucesso!

Inserindo 30 FAQs na tabela 'marketing_rag'...

Limpando tabela 'marketing_rag'...
Tabela 'marketing_rag' limpa com sucesso!
30 FAQs inseridos com sucesso no Supabase!

================================================================================
INGESTAO CONCLUIDA COM SUCESSO!
================================================================================

Estatisticas:
   - Arquivo processado: plantie.md
   - FAQs gerados: 30
   - Tabela: marketing_rag
   - Modo clear: Sim

FAQs por categoria:
   - Policies & Compliance: 17
   - Billing & Account: 4
   - Product Info: 3
   - How-To & Configuration: 3
   - General: 2
   - Troubleshooting: 1

================================================================================
RESUMO DE USO DE TOKENS
================================================================================

LLM (Gemini 2.5 Flash):
   - Tokens de entrada: 6,311
   - Tokens de saida: 9,675
   - Total LLM: 15,986

Embeddings (Gemini Embedding):
   - Tokens processados: 4,276

TOTAL GERAL: 20,262 tokens
================================================================================
```

---

## ğŸ“Š Estrutura dos Dados no Supabase

### Esquema da Tabela

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | UUID | ID Ãºnico (auto-gerado) |
| `content` | TEXT | Resposta do FAQ (o que serÃ¡ retornado) |
| `metadata` | JSONB | Metadados estruturados |
| `embedding` | VECTOR(768) | Vetor semÃ¢ntico |

### Exemplo de Registro

```json
{
  "id": "a1b2c3d4-...",
  "content": "Para visualizar suas notas fiscais, acesse o menu superior direito...",
  "metadata": {
    "question": "Como acessar e visualizar as notas fiscais?",
    "synthetic_variations": [
      "Onde baixo meus boletos?",
      "Caminho para faturamento",
      "Ver histÃ³rico de pagamentos"
    ],
    "category": "Billing & Account",
    "tags": ["notas fiscais", "faturamento", "boletos", "menu"],
    "audience": "End-User",
    "confidence_score": 1.0
  },
  "embedding": [0.123, -0.456, 0.789, ...]
}
```

---

## ğŸ” Casos de Uso

### 1. IngestÃ£o de DocumentaÃ§Ã£o TÃ©cnica

```bash
python Agente_FAQ.py --input docs/api-reference.md --table tech_docs_faq
```

**Entrada**: DocumentaÃ§Ã£o tÃ©cnica bruta com explicaÃ§Ãµes de endpoints, parÃ¢metros, etc.

**SaÃ­da**: FAQs estruturados como:
- "Como autenticar na API?"
- "Quais sÃ£o os limites de rate limit?"
- "Como fazer paginaÃ§Ã£o nos resultados?"

### 2. Base de Conhecimento de Suporte

```bash
python Agente_FAQ.py --input support/troubleshooting.md --table support_kb --clear
```

**Entrada**: Artigos de troubleshooting do site de suporte

**SaÃ­da**: FAQs categorizados como `Troubleshooting` com soluÃ§Ãµes para erros comuns

### 3. PolÃ­ticas e Compliance

```bash
python Agente_FAQ.py --input legal/terms-of-service.md --table legal_kb
```

**Entrada**: Termos de uso, polÃ­tica de privacidade

**SaÃ­da**: FAQs em linguagem simples sobre polÃ­ticas da empresa

---

## âš™ï¸ ConfiguraÃ§Ãµes e OtimizaÃ§Ãµes

### Modelos Utilizados

**LLM: Gemini 2.5 Flash**
- **PropÃ³sito**: ExtraÃ§Ã£o estruturada de FAQs
- **Temperature**: 0 (determinÃ­stico)
- **Vantagens**: RÃ¡pido, custo-efetivo, boa qualidade

**Embeddings: Gemini Embedding-001**
- **DimensÃµes**: 3072 (default), mas pode usar 768 ou 1536
- **Suporta**: 100+ idiomas
- **Vantagens**: SOTA em multilingual, 2048 tokens de entrada

### Estimativa de Custos

**PreÃ§o Gemini Embedding-001**: $0.15 por 1M tokens

**Exemplo de cÃ¡lculo** (baseado na execuÃ§Ã£o de teste):
- LLM: 15.986 tokens
- Embeddings: 4.276 tokens
- **Total**: 20.262 tokens

**Custo estimado para embeddings**: 
```
4.276 tokens Ã— ($0.15 / 1.000.000) = $0.00064 (~R$ 0,0036)
```

Para processar 100 documentos similares:
```
20.262 tokens Ã— 100 = ~2M tokens
Custo embeddings: ~$0.30
```

### OtimizaÃ§Ãµes PossÃ­veis

**1. Batch Processing**: Processar mÃºltiplos arquivos em uma execuÃ§Ã£o
```python
for file in glob.glob("docs/*.md"):
    content = load_markdown_file(file)
    # ... processo
```

**2. Cache de Embeddings**: NÃ£o regerar embeddings se conteÃºdo nÃ£o mudou
```python
# Usar hash do conteÃºdo como chave
content_hash = hashlib.md5(content.encode()).hexdigest()
```

**3. Chunking de Documentos Grandes**: Dividir docs >100k chars
```python
if len(content) > 100000:
    chunks = split_text(content, max_size=50000)
```

---

## ğŸ› Tratamento de Erros

### Erros Comuns

**1. `FileNotFoundError`**
```
Arquivo nÃ£o encontrado: documento.md
```
**SoluÃ§Ã£o**: Verificar caminho do arquivo

**2. `JSONDecodeError`**
```
Erro ao fazer parse do JSON: Expecting value: line 1 column 1 (char 0)
```
**SoluÃ§Ã£o**: LLM retornou resposta invÃ¡lida. Verificar system prompt ou tentar novamente.

**3. `ValidationError`**
```
Erro de validacao Pydantic: field required
```
**SoluÃ§Ã£o**: JSON nÃ£o segue estrutura esperada. Revisar models.py.

**4. `GoogleGenerativeAIError`**
```
Error embedding content (NOT_FOUND): 404 NOT_FOUND
```
**SoluÃ§Ã£o**: Modelo de embedding incorreto. Usar `models/gemini-embedding-001`.

**5. `ValueError` (VariÃ¡veis de ambiente)**
```
SUPABASE_URL e SUPABASE_SERVICE_KEY devem estar definidos no .env
```
**SoluÃ§Ã£o**: Criar arquivo `.env` com as credenciais.

---

## ğŸ” SeguranÃ§a

### Boas PrÃ¡ticas

âœ… **Usar variÃ¡veis de ambiente** para credenciais (nunca commitar `.env`)

âœ… **Service Key do Supabase** apenas em servidor (nÃ£o expor no frontend)

âœ… **ValidaÃ§Ã£o de entrada** com Pydantic para prevenir dados malformados

âœ… **Rate limiting** se processar muitos arquivos (evitar throttling da API)

### PermissÃµes NecessÃ¡rias

**Google AI**:
- Acesso Ã  API Gemini (chave vÃ¡lida)
- Quota suficiente para tokens

**Supabase**:
- PermissÃ£o de INSERT na tabela
- PermissÃ£o de DELETE se usar `--clear`
- Service Key com privilÃ©gios adequados

---

## ğŸ“ˆ MÃ©tricas e Monitoramento

### O que Rastrear

1. **Tokens por documento**: Verificar se estÃ¡ dentro do esperado
2. **NÃºmero de FAQs extraÃ­dos**: Avaliar qualidade da extraÃ§Ã£o
3. **DistribuiÃ§Ã£o por categoria**: Verificar balanceamento
4. **Tempo de execuÃ§Ã£o**: Identificar gargalos
5. **Taxa de erros**: JSON parsing, validaÃ§Ã£o

### Exemplo de Log

```python
{
    "timestamp": "2026-02-10T16:26:46Z",
    "arquivo": "plantie.md",
    "chars_input": 20608,
    "faqs_gerados": 30,
    "tokens_llm": 15986,
    "tokens_embeddings": 4276,
    "tokens_total": 20262,
    "tempo_execucao_ms": 69358,
    "categorias": {
        "Policies & Compliance": 17,
        "Billing & Account": 4,
        "Product Info": 3
    }
}
```

---

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Testes Recomendados

**1. Teste com Documento Pequeno**
```bash
echo "# FAQ\n\nComo fazer login?\n\nAcesse o site e clique em Entrar." > test.md
python Agente_FAQ.py --input test.md --table test_table --clear
```

**2. Teste de CategorizaÃ§Ã£o**
- Verificar se FAQs estÃ£o nas categorias corretas
- Validar que synthetic_variations fazem sentido

**3. Teste de Busca SemÃ¢ntica** (apÃ³s ingestÃ£o)
```python
# Usar agent_rag.py para buscar
result = buscar_faq("preciso redefinir minha senha")
# Deve retornar FAQ sobre reset de senha
```

---

## ğŸ“ Conceitos TÃ©cnicos

### RAG (Retrieval-Augmented Generation)

Este script Ã© a **parte de INGESTÃƒO** de um sistema RAG:

1. **IngestÃ£o** (Agente_FAQ.py) â† VocÃª estÃ¡ aqui
   - Processa documentos
   - Gera embeddings
   - Armazena no banco vetorial

2. **Retrieval** (agent_rag.py)
   - Recebe pergunta do usuÃ¡rio
   - Busca FAQs similares no banco
   - Retorna as melhores respostas

3. **Generation** (chatbot)
   - Usa contexto recuperado
   - Gera resposta personalizada

### Embeddings Vetoriais

**O que sÃ£o**: RepresentaÃ§Ãµes numÃ©ricas de texto que capturam significado semÃ¢ntico.

**Como funcionam**:
```
Texto: "Como resetar senha?"
       â†“ (Gemini Embedding)
Vetor: [0.123, -0.456, 0.789, ..., 0.234]  (768 dimensÃµes)
```

**Similaridade**:
```python
# Perguntas semanticamente similares tÃªm vetores prÃ³ximos
pergunta1 = "Como recuperar minha senha?"  â†’ vetor1
pergunta2 = "Esqueci minha senha"          â†’ vetor2
# cosine_similarity(vetor1, vetor2) = 0.92 (muito similar!)
```

### Query Expansion

**Problema**: UsuÃ¡rio pode perguntar de formas diferentes.

**SoluÃ§Ã£o**: Gerar variaÃ§Ãµes sintÃ©ticas para capturar mais formas de busca.

**Exemplo**:
```
Pergunta original: "Como resetar a senha?"

VariaÃ§Ãµes geradas:
- "esqueci minha senha o que fazer" (leigo)
- "recuperar acesso conta" (keyword)
- "problema login senha incorreta" (sintoma)
```

Quando o usuÃ¡rio buscar qualquer uma dessas formas, o FAQ serÃ¡ encontrado!

---

## ğŸ”„ Fluxo de Dados Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SISTEMA COMPLETO RAG                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. INGESTÃƒO (Agente_FAQ.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                        â”‚
   docs/*.md â”€â”€â–º LLM â”€â”€â–º FAQs â”€â”€â–º Embeddings â”€â”€â–º Supabase              â”‚
   (scraped)    (Gemini) (JSON)  (vectors)     (pgvector)             â”‚
                                                                        â”‚
2. CONSULTA (agent_rag.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                                                        â”‚
   Pergunta â”€â”€â–º Embedding â”€â”€â–º Busca â”€â”€â–º Top-K FAQs â”€â”€â–º Resposta       â”‚
   usuÃ¡rio     (vetor)       (similar)  (relevantes)   (contextual)    â”‚
                                                                        â”‚
3. INTERFACE (Chatbot/API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                        
   Frontend â”€â”€â–º API â”€â”€â–º RAG â”€â”€â–º Resposta â”€â”€â–º UsuÃ¡rio                   
   (React)    (Flask)  (agent) (markdown)   (satisfeito!)              
```

---

## ğŸ“ Notas Finais

### Quando Usar Este Script

âœ… **Ideal para**:
- DocumentaÃ§Ã£o tÃ©cnica extensa
- Base de conhecimento de suporte
- FAQs corporativos
- PolÃ­ticas e compliance
- Manuais de produtos

âŒ **NÃ£o ideal para**:
- Dados tabulares (usar CSV/database diretamente)
- CÃ³digo-fonte (usar ferramentas de code search)
- Dados time-sensitive que mudam frequentemente

### PrÃ³ximos Passos

ApÃ³s executar este script, vocÃª pode:

1. **Consultar os FAQs** usando `agent_rag.py`
2. **Integrar com chatbot** para atendimento automÃ¡tico
3. **Criar API REST** para expor busca de FAQs
4. **Adicionar UI** para gerenciar base de conhecimento
5. **Configurar pipeline CI/CD** para auto-ingestÃ£o

---

## ğŸ¤ Contribuindo

Para melhorar este script:

1. **Adicionar suporte a mÃºltiplos arquivos** em uma execuÃ§Ã£o
2. **Implementar cache** de embeddings
3. **Adicionar testes unitÃ¡rios**
4. **Criar CLI mais rica** (progress bars, logs JSON)
5. **Suportar outros formatos** (PDF, HTML, DOCX)

---

## ğŸ“š ReferÃªncias

- [LangChain Documentation](https://python.langchain.com/)
- [Google AI Gemini API](https://ai.google.dev/)
- [Supabase Vector Search](https://supabase.com/docs/guides/ai)
- [Pydantic Documentation](https://docs.pydantic.dev/)

---

**Criado em**: Fevereiro 2026  
**VersÃ£o**: 1.0  
**Autor**: Sistema de IngestÃ£o AgÃªntica
